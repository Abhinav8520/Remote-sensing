{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ECdTEVqnfU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25ECdTEVqnfU",
    "outputId": "51072933-bafd-423a-f532-304ce37b2243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa67228-de65-420b-b6a7-f824671bc2ee",
   "metadata": {
    "id": "cfa67228-de65-420b-b6a7-f824671bc2ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import load,dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pydot\n",
    "from numpy import argmax\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import  pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3daee9-a2b4-4abd-80e4-dfebea9f629a",
   "metadata": {
    "id": "6c3daee9-a2b4-4abd-80e4-dfebea9f629a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = r'C:\\Users\\Abhinav\\Desktop\\Masters Assignments\\MLE project\\UCM_captions'\n",
    "split_path = 'drive/My Drive/MLE NEW/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9874038-1364-43a3-889a-ab48e2286b23",
   "metadata": {
    "id": "f9874038-1364-43a3-889a-ab48e2286b23",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def prepare_and_split_dataset(dataset_path, split_path):\n",
    "\n",
    "    os.makedirs(os.path.join(split_path, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_path, 'validation'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_path, 'test'), exist_ok=True)\n",
    "\n",
    "    # Get all file entries in the dataset directory and filter out directories\n",
    "    all_entries = os.listdir(dataset_path)\n",
    "    image_paths = [os.path.join(dataset_path, fname) for fname in all_entries if os.path.isfile(os.path.join(dataset_path, fname))]\n",
    "\n",
    "    labels = [os.path.splitext(fname)[0] for fname in all_entries if os.path.isfile(os.path.join(dataset_path, fname))]\n",
    "\n",
    "    # Split the dataset into training, validation, and testing sets\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "        test_paths, test_labels, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    return train_paths, val_paths, test_paths, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dec03f-f42c-469a-8e4c-9764b485f3dc",
   "metadata": {
    "id": "d8dec03f-f42c-469a-8e4c-9764b485f3dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_files(file_paths, labels, target_dir):\n",
    "    for path, label in zip(file_paths, labels):\n",
    "        label_dir = os.path.join(target_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        shutil.copy(path, os.path.join(label_dir, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fd2fc-24dc-41c1-9b9a-1d7be2534a61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "fd2fd2fc-24dc-41c1-9b9a-1d7be2534a61",
    "outputId": "00a8586b-05ef-489a-fb45-b8fe0c037bcb",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Abhinav\\\\Desktop\\\\Masters Assignments\\\\MLE project\\\\UCM_captions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-31aa50b69c28>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_and_split_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-0716eaafcc5f>\u001b[0m in \u001b[0;36mprepare_and_split_dataset\u001b[0;34m(dataset_path, split_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Get all file entries in the dataset directory and filter out directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mall_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_entries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Abhinav\\\\Desktop\\\\Masters Assignments\\\\MLE project\\\\UCM_captions'"
     ]
    }
   ],
   "source": [
    "train_paths, val_paths, test_paths, train_labels, val_labels, test_labels = prepare_and_split_dataset(dataset_path, split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f001-ac44-4903-aa54-507832d65e5d",
   "metadata": {
    "id": "c359f001-ac44-4903-aa54-507832d65e5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "move_files(train_paths, train_labels, os.path.join(split_path, 'train'))\n",
    "move_files(val_paths, val_labels, os.path.join(split_path, 'validation'))\n",
    "move_files(test_paths, test_labels, os.path.join(split_path, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5449e-ebf7-414e-b0d0-22c2fbec0e68",
   "metadata": {
    "id": "06f5449e-ebf7-414e-b0d0-22c2fbec0e68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Create the encoder\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# all_labels = np.array(train_labels + val_labels + test_labels).reshape(-1, 1)\n",
    "# encoder.fit(all_labels)\n",
    "\n",
    "# # Transform the labels into one-hot encoded arrays\n",
    "# train_labels_onehot = encoder.transform(np.array(train_labels).reshape(-1, 1))\n",
    "# val_labels_onehot = encoder.transform(np.array(val_labels).reshape(-1, 1))\n",
    "# test_labels_onehot = encoder.transform(np.array(test_labels).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2c017-fd5c-4da9-bb59-bb74d1699aaf",
   "metadata": {
    "id": "b5a2c017-fd5c-4da9-bb59-bb74d1699aaf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet152, ResNet152_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a10bab-25df-43c3-9df0-64e1a122fd51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2a10bab-25df-43c3-9df0-64e1a122fd51",
    "outputId": "f09b7747-f651-4cb6-f2df-3abc7a053629",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad169b75-5398-47a9-ad86-edd469546095",
   "metadata": {
    "id": "ad169b75-5398-47a9-ad86-edd469546095",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_model(device):\n",
    "    model = resnet152(weights=ResNet152_Weights.IMAGENET1K_V1)\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2380a33-adad-4078-9069-7a02643c0a69",
   "metadata": {
    "id": "f2380a33-adad-4078-9069-7a02643c0a69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca79e7-fcda-4a41-8a79-a7d64c624bab",
   "metadata": {
    "id": "c5ca79e7-fcda-4a41-8a79-a7d64c624bab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c10666-1b83-4928-b9bc-98d0237cca66",
   "metadata": {
    "id": "e0c10666-1b83-4928-b9bc-98d0237cca66",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(image_paths, model, preprocess, batch_size=32):\n",
    "    dataset = ImageDataset(image_paths, transform=preprocess)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    features_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images in dataloader:\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            features_np = features.detach().cpu().numpy()\n",
    "            # Change shape from (batch_size, 2048) to (batch_size, 1, 2048)\n",
    "            features_np = features_np.reshape(features_np.shape[0], 1, features_np.shape[1])\n",
    "            features_list.append(features_np)\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640b43b-3057-4539-85ed-00d5600fde26",
   "metadata": {
    "id": "e640b43b-3057-4539-85ed-00d5600fde26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_features(features, labels, save_dir, set_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = os.path.join(save_dir, f'{set_name}_features.pkl')\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump({'features': features, 'labels': labels}, f)\n",
    "    print(f'Features and labels saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efaaf77-e8ec-408f-aadb-0c62c4fccf53",
   "metadata": {
    "id": "8efaaf77-e8ec-408f-aadb-0c62c4fccf53",
    "outputId": "f857ad82-8a22-4f71-f023-f1ad1bfe783b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels saved to /home/a.kapavarapu/ondemand/Project/New_features_CNN/train_features.pkl\n",
      "Features and labels saved to /home/a.kapavarapu/ondemand/Project/New_features_CNN/val_features.pkl\n",
      "Features and labels saved to /home/a.kapavarapu/ondemand/Project/New_features_CNN/test_features.pkl\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(device)\n",
    "\n",
    "# Example usage, assuming train_paths, val_paths, test_paths, and their corresponding labels are defined\n",
    "save_dir = '/home/a.kapavarapu/ondemand/Project/New_features_CNN'\n",
    "\n",
    "train_features = extract_features(train_paths, model, preprocess)\n",
    "save_features(train_features, train_labels, save_dir, 'train')\n",
    "\n",
    "val_features = extract_features(val_paths, model, preprocess)\n",
    "save_features(val_features, val_labels, save_dir, 'val')\n",
    "\n",
    "test_features = extract_features(test_paths, model, preprocess)\n",
    "save_features(test_features, test_labels, save_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b066d-54b0-4de3-8180-bf73459b5518",
   "metadata": {
    "id": "b27b066d-54b0-4de3-8180-bf73459b5518",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def transform_pkl_file(filename):\n",
    "    # Load the original .pkl file\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    # Transform the data\n",
    "    new_data = {label: feature for label, feature in zip(data['labels'], data['features'])}\n",
    "\n",
    "    # Save the transformed data\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(new_data, file)\n",
    "\n",
    "train_filename = '/home/a.kapavarapu/ondemand/Project/New_features_CNN/train_features.pkl'\n",
    "val_filename = '/home/a.kapavarapu/ondemand/Project/New_features_CNN/val_features.pkl'\n",
    "test_filename = '/home/a.kapavarapu/ondemand/Project/New_features_CNN/test_features.pkl'\n",
    "\n",
    "transform_pkl_file(train_filename)\n",
    "transform_pkl_file(val_filename)\n",
    "transform_pkl_file(test_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35daf1e-f7a5-48d7-9421-022154606509",
   "metadata": {
    "id": "a35daf1e-f7a5-48d7-9421-022154606509",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = '/home/a.kapavarapu/ondemand/Project/New_features_CNN/train_features.pkl'\n",
    "# with open(filename, 'rb') as file:\n",
    "#     # Load the content of the file into a variable\n",
    "#     data = pickle.load(file)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819583f0-4ea2-43e2-91f0-3c4874b97e2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "819583f0-4ea2-43e2-91f0-3c4874b97e2e",
    "outputId": "a69adcfa-53b6-44e6-8d8f-796ec2521fa6",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drive/My Drive/MLE_NEW/Captions/new_captions.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-719ffa2b19a8>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcaptions_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/My Drive/MLE_NEW/Captions/new_captions.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcaptions_by_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_captions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-719ffa2b19a8>\u001b[0m in \u001b[0;36mread_captions\u001b[0;34m(captions_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_captions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcaptions_by_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/MLE_NEW/Captions/new_captions.txt'"
     ]
    }
   ],
   "source": [
    "def read_captions(captions_file):\n",
    "    captions_by_id = {}\n",
    "    with open(captions_file, 'r') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:  # Skip empty lines\n",
    "                continue\n",
    "            parts = line.split(' ', 1)\n",
    "            if len(parts) != 2:\n",
    "                print(f\"Warning: Line {line_number} formatted incorrectly: '{line}'\")\n",
    "                continue\n",
    "            image_id, caption = parts\n",
    "            if image_id not in captions_by_id:\n",
    "                captions_by_id[image_id] = []\n",
    "            captions_by_id[image_id].append(caption)\n",
    "    return captions_by_id\n",
    "\n",
    "captions_file = 'drive/My Drive/MLE_NEW/Captions/new_captions.txt'\n",
    "captions_by_id = read_captions(captions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a51a8-2409-4668-9ce9-349e4935c1c0",
   "metadata": {
    "id": "7a2a51a8-2409-4668-9ce9-349e4935c1c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_ids_from_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return list(data.keys())\n",
    "\n",
    "train_ids = get_image_ids_from_pkl('/home/a.kapavarapu/ondemand/Project/New_features_CNN/train_features.pkl')\n",
    "val_ids = get_image_ids_from_pkl('/home/a.kapavarapu/ondemand/Project/New_features_CNN/val_features.pkl')\n",
    "test_ids = get_image_ids_from_pkl('/home/a.kapavarapu/ondemand/Project/New_features_CNN/test_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d3f842-ccce-4212-b690-6f54aa3a60df",
   "metadata": {
    "id": "49d3f842-ccce-4212-b690-6f54aa3a60df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_captions_for_set(image_ids, captions_by_id):\n",
    "    captions = []\n",
    "    for image_id in image_ids:\n",
    "        if image_id in captions_by_id:\n",
    "            for caption in captions_by_id[image_id]:\n",
    "                captions.append(f\"{image_id} {caption}\")\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326230f-b355-439d-a9b8-1cc6fcbb5baa",
   "metadata": {
    "id": "9326230f-b355-439d-a9b8-1cc6fcbb5baa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_captions_to_file(captions, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for caption in captions:\n",
    "            file.write(f\"{caption}\\n\")\n",
    "\n",
    "write_captions_to_file(filter_captions_for_set(train_ids, captions_by_id), '/home/a.kapavarapu/ondemand/Project/Dataset/train_captions.txt')\n",
    "write_captions_to_file(filter_captions_for_set(val_ids, captions_by_id), '/home/a.kapavarapu/ondemand/Project/Dataset/val_captions.txt')\n",
    "write_captions_to_file(filter_captions_for_set(test_ids, captions_by_id), '/home/a.kapavarapu/ondemand/Project/Dataset/test_captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d65dc-3d39-43fc-a265-b06a99f18d25",
   "metadata": {
    "id": "2c1d65dc-3d39-43fc-a265-b06a99f18d25"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac232ee2-d082-400b-9e84-7c4e62737e2f",
   "metadata": {
    "id": "ac232ee2-d082-400b-9e84-7c4e62737e2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad802e6f-156f-465c-8d48-175a21399305",
   "metadata": {
    "id": "ad802e6f-156f-465c-8d48-175a21399305"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510393d-47fe-49a6-8e6c-f73228c29548",
   "metadata": {
    "id": "6510393d-47fe-49a6-8e6c-f73228c29548"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
